{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u0001d\u0002Using stash (v0.27.2-37-g0621d871) endpoint at http://localhost:6969/graphql\n",
      "\u0001d\u0002Persisting Connection to Stash with ApiKey...\n",
      "\u0001d\u0002Using stash (v0.27.2-37-g0621d871) endpoint at http://localhost:6969/graphql\n",
      "\u0001d\u0002Persisting Connection to Stash with ApiKey...\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "from libraries.scene_states import SceneState  # Changed from FaceDatasetBuilder to scene_states\n",
    "from libraries.FaceDatasetBuilder import FaceDatasetBuilder\n",
    "from libraries.client_stashapp import get_stashapp_client, StashAppClient\n",
    "\n",
    "def get_stashdb_performer(performer):\n",
    "    \"\"\"Extract StashDB ID and name from performer data\"\"\"\n",
    "    for stash_id in performer[\"stashapp_performers_stash_ids\"]:\n",
    "        if stash_id[\"endpoint\"] == \"https://stashdb.org/graphql\":\n",
    "            return {\n",
    "                'stash_id': stash_id[\"stash_id\"],\n",
    "                'name': performer[\"stashapp_performers_name\"]\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Process a scene\n",
    "def process_scene(scene):\n",
    "    # Get performers with their StashDB IDs\n",
    "    performers = []\n",
    "    for performer in scene[\"stashapp_performers\"]:\n",
    "        stashdb_info = get_stashdb_performer(performer)\n",
    "        if stashdb_info:\n",
    "            performers.append(f\"{stashdb_info['stash_id']} - {stashdb_info['name']}\")\n",
    "    \n",
    "    # Process the scene\n",
    "    if performers:\n",
    "        return builder.process_scene(\n",
    "            video_path=scene[\"stashapp_primary_file_path\"],\n",
    "            scene_id=scene[\"stashapp_stashdb_id\"],\n",
    "            performers=performers\n",
    "        )\n",
    "    return 0\n",
    "\n",
    "# Initialize builder\n",
    "builder = FaceDatasetBuilder()\n",
    "\n",
    "stash = get_stashapp_client()\n",
    "stash_client = StashAppClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_performers = stash_client.get_performers()\n",
    "performer = all_performers.filter(pl.col(\"stashapp_name\").str.contains(\"Alexis Crystal\")).to_dicts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_reality_tag = stash.find_tag(\"Virtual Reality\")[\"id\"]\n",
    "\n",
    "sample_scenes = stash_client.find_scenes({\n",
    "    \"performers\": {\"value\": [performer[\"stashapp_id\"]], \"excludes\": [], \"modifier\": \"INCLUDES\" },\n",
    "    \"tags\": {\"value\": [], \"excludes\": [virtual_reality_tag], \"modifier\": \"INCLUDES\" }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scenes: 1143\n",
      "Already processed: 0\n",
      "Remaining to process: 964\n"
     ]
    }
   ],
   "source": [
    "# Find the processed scene IDs from file system\n",
    "if os.path.exists(builder.structure['scenes'][SceneState.FACES_EXTRACTED.value]):\n",
    "    processed_scenes = set(os.listdir(os.path.join(builder.structure['scenes'][SceneState.FACES_EXTRACTED.value])))\n",
    "else:\n",
    "    # If directory doesn't exist, create it and start with empty set\n",
    "    os.makedirs(os.path.join(builder.structure['scenes'], SceneState.FACES_EXTRACTED.value), exist_ok=True)\n",
    "    processed_scenes = set()\n",
    "\n",
    "# Filter out processed scenes from sample_scenes\n",
    "unprocessed_scenes = sample_scenes.filter(\n",
    "    ~pl.col(\"stashapp_stashdb_id\").is_in(processed_scenes)\n",
    ")\n",
    "\n",
    "print(f\"Total scenes: {len(sample_scenes)}\")\n",
    "print(f\"Already processed: {len(processed_scenes)}\")\n",
    "print(f\"Remaining to process: {len(unprocessed_scenes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenes per drive:\n",
      "X:: 1 scenes\n",
      "Y:: 0 scenes\n",
      "Z:: 0 scenes\n",
      "W:: 0 scenes\n",
      "\n",
      "Created 1 JSON files in H:\\Faces\\dataset\\scenes\\1_pending\n"
     ]
    }
   ],
   "source": [
    "# Get a balanced batch of scenes to process\n",
    "MAX_SCENES = 1  # Total scenes to process\n",
    "MAX_PER_DRIVE = 1  # Maximum concurrent scenes per HDD\n",
    "STORAGE_DRIVES = ['X:', 'Y:', 'Z:', 'W:']  # Available drives for processing\n",
    "\n",
    "# First, group all unprocessed scenes by drive\n",
    "drive_scenes = {drive: [] for drive in STORAGE_DRIVES}  # Initialize all drives\n",
    "\n",
    "# Group scenes by drive\n",
    "for scene in unprocessed_scenes.to_dicts():\n",
    "    performers = []\n",
    "    for performer in scene[\"stashapp_performers\"]:\n",
    "        stashdb_info = get_stashdb_performer(performer)\n",
    "        if stashdb_info:\n",
    "            performers.append(f\"{stashdb_info['stash_id']} - {stashdb_info['name']}\")\n",
    "    \n",
    "    if performers:\n",
    "        video_path = scene[\"stashapp_primary_file_path\"]\n",
    "        drive = os.path.splitdrive(video_path)[0].upper()\n",
    "        \n",
    "        if drive in STORAGE_DRIVES:  # Only process from our storage drives\n",
    "            scene['video_path'] = video_path\n",
    "            scene['performers'] = performers\n",
    "            drive_scenes[drive].append(scene)\n",
    "\n",
    "# Simple round-robin selection\n",
    "scenes_to_process = []\n",
    "for i in range(MAX_SCENES):\n",
    "    drive = STORAGE_DRIVES[i % len(STORAGE_DRIVES)]\n",
    "    if drive_scenes[drive]:  # If this drive has any scenes left\n",
    "        scenes_to_process.append(drive_scenes[drive].pop(0))\n",
    "\n",
    "# Print scene distribution\n",
    "print(\"Scenes per drive:\")\n",
    "drive_counts = {}\n",
    "for scene in scenes_to_process:\n",
    "    drive = os.path.splitdrive(scene['video_path'])[0].upper()\n",
    "    drive_counts[drive] = drive_counts.get(drive, 0) + 1\n",
    "\n",
    "for drive in STORAGE_DRIVES:\n",
    "    print(f\"{drive}: {drive_counts.get(drive, 0)} scenes\")\n",
    "\n",
    "# Create JSON files in pending directory\n",
    "pending_dir = Path(\"H:\\\\Faces\\\\dataset\") / 'scenes' / SceneState.PENDING.value\n",
    "os.makedirs(pending_dir, exist_ok=True)\n",
    "\n",
    "for scene in scenes_to_process:\n",
    "    scene_id = scene['stashapp_stashdb_id']\n",
    "    scene_data = {\n",
    "        'video_path': scene['video_path'],\n",
    "        'performers': scene['performers']\n",
    "    }\n",
    "    \n",
    "    json_path = pending_dir / f\"{scene_id}.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(scene_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nCreated {len(scenes_to_process)} JSON files in {pending_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.prepare_scenes import prepare_scenes_for_performer\n",
    "\n",
    "# Queue scenes for processing\n",
    "base_dir = \"H:\\\\Faces\\\\dataset\"\n",
    "stats = prepare_scenes_for_performer(\"Alexis Crystal\", base_dir)\n",
    "\n",
    "print(f\"Total scenes found: {stats['total_scenes']}\")\n",
    "print(f\"Already processed: {stats['already_processed']}\")\n",
    "print(f\"Newly queued: {stats['newly_queued']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of scenes to process\n",
    "scenes_to_process = []\n",
    "drive_counts = {}  # Track number of scenes per drive\n",
    "\n",
    "# Get scenes and count per drive\n",
    "for scene in unprocessed_scenes.head(12).to_dicts():\n",
    "    performers = []\n",
    "    for performer in scene[\"stashapp_performers\"]:\n",
    "        stashdb_info = get_stashdb_performer(performer)\n",
    "        if stashdb_info:\n",
    "            performers.append(f\"{stashdb_info['stash_id']} - {stashdb_info['name']}\")\n",
    "    \n",
    "    if performers:\n",
    "        video_path = scene[\"stashapp_primary_file_path\"]\n",
    "        drive = os.path.splitdrive(video_path)[0].upper()\n",
    "        \n",
    "        if drive not in drive_counts:\n",
    "            drive_counts[drive] = 0\n",
    "        drive_counts[drive] += 1\n",
    "        \n",
    "        scene['video_path'] = video_path\n",
    "        scene['performers'] = performers\n",
    "        scenes_to_process.append(scene)\n",
    "\n",
    "print(\"Scenes per drive:\")\n",
    "for drive, count in drive_counts.items():\n",
    "    print(f\"{drive}: {count} scenes\")\n",
    "\n",
    "# Process multiple scenes in parallel\n",
    "builder = FaceDatasetBuilder(max_concurrent_scenes=8)  # Total concurrent scenes\n",
    "results = builder.process_multiple_scenes(scenes_to_process)\n",
    "\n",
    "# Print results with more detailed error information\n",
    "for result in results:\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"Scene {result['scene_id']}: Extracted {result['faces_extracted']} faces\")\n",
    "    else:\n",
    "        print(f\"Scene {result['scene_id']}: Error - {result['error']}\")\n",
    "        if 'stderr' in result:\n",
    "            print(f\"ffmpeg stderr:\\n{result['stderr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from line_profiler import LineProfiler\n",
    "\n",
    "# Create line profiler\n",
    "lp = LineProfiler()\n",
    "\n",
    "# Profile specific methods\n",
    "lp.add_function(builder.process_scene)\n",
    "lp_wrapper = lp(builder.process_scene)\n",
    "\n",
    "# Run the profiled code\n",
    "faces_extracted = lp_wrapper(\n",
    "    sample_scene[\"stashapp_primary_file_path\"],\n",
    "    sample_scene['stashapp_stashdb_id'],\n",
    "    performers\n",
    ")\n",
    "\n",
    "# Print the line-by-line stats\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process your sample scene\n",
    "faces_extracted = process_scene(sample_scene)\n",
    "print(f\"Extracted {faces_extracted} faces\")\n",
    "\n",
    "# Verify directories exist\n",
    "import os\n",
    "base_dir = \"H:\\\\Faces\\\\dataset\"\n",
    "print(\"\\nDirectory structure:\")\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    level = root.replace(base_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    if level < 2:  # Only show first two levels\n",
    "        for d in dirs:\n",
    "            print(f\"{indent}    {d}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = FaceDatasetBuilder(max_concurrent_scenes=4)  # Adjust based on your storage devices\n",
    "\n",
    "# After manually moving faces to correct performer directories in Windows Explorer\n",
    "scene_stashdb_id = \"7a39d783-a458-4c6d-8407-7565e09a3c12\"\n",
    "builder.verify_scene(scene_stashdb_id)\n",
    "\n",
    "# Check how many faces we have for each performer\n",
    "face_counts = builder.get_performer_face_count()\n",
    "for performer, count in sorted(face_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{performer}: {count} faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversifying selected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imagehash\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def deduplicate_faces(face_dir, max_faces=100):\n",
    "    \"\"\"\n",
    "    Cluster similar faces and keep the most representative ones\n",
    "    \"\"\"\n",
    "    # Calculate perceptual hashes for all images\n",
    "    hashes = []\n",
    "    paths = []\n",
    "    for img_path in os.listdir(face_dir):\n",
    "        if img_path.endswith('.jpg'):\n",
    "            full_path = os.path.join(face_dir, img_path)\n",
    "            try:\n",
    "                img_hash = imagehash.average_hash(Image.open(full_path))\n",
    "                hashes.append(img_hash)\n",
    "                paths.append(full_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Convert hashes to feature vectors\n",
    "    hash_vectors = np.array([[int(b) for b in str(h)] for h in hashes])\n",
    "    \n",
    "    # Cluster similar images\n",
    "    n_clusters = min(max_faces, len(paths))\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(hash_vectors)\n",
    "    \n",
    "    # Keep images closest to cluster centers\n",
    "    kept_images = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_indices = np.where(clusters == i)[0]\n",
    "        if len(cluster_indices) > 0:\n",
    "            # Find image closest to cluster center\n",
    "            center_idx = cluster_indices[0]\n",
    "            kept_images.append(paths[center_idx])\n",
    "    \n",
    "    return kept_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "def get_diverse_faces(face_dir, max_faces=100):\n",
    "    \"\"\"\n",
    "    Select faces with diverse angles and expressions\n",
    "    \"\"\"\n",
    "    faces_data = []\n",
    "    for img_path in os.listdir(face_dir):\n",
    "        if img_path.endswith('.jpg'):\n",
    "            full_path = os.path.join(face_dir, img_path)\n",
    "            try:\n",
    "                # Get face landmarks\n",
    "                image = face_recognition.load_image_file(full_path)\n",
    "                landmarks = face_recognition.face_landmarks(image)\n",
    "                if landmarks:\n",
    "                    # Calculate features from landmarks (e.g., eye distance, mouth openness)\n",
    "                    features = extract_features_from_landmarks(landmarks[0])\n",
    "                    faces_data.append((full_path, features))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Cluster faces based on features\n",
    "    features_array = np.array([f for _, f in faces_data])\n",
    "    n_clusters = min(max_faces, len(faces_data))\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(features_array)\n",
    "    \n",
    "    # Select representative faces from each cluster\n",
    "    diverse_faces = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_indices = np.where(clusters == i)[0]\n",
    "        if len(cluster_indices) > 0:\n",
    "            diverse_faces.append(faces_data[cluster_indices[0]][0])\n",
    "    \n",
    "    return diverse_faces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
