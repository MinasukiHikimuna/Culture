{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nfrom pathlib import Path\n\nimport polars as pl\n\n\nsys.path.append(str(Path.cwd().parent))\n\nfrom libraries.client_stashapp import StashAppClient, get_stashapp_client\n\n\n# Initialize Stash client\nstash_client = StashAppClient()\nstash_raw_client = get_stashapp_client()\n\ndef find_csv_files(base_paths):\n    \"\"\"Find all .Scenes.csv files in the given base paths\"\"\"\n    csv_files = []\n\n    for base_path in base_paths:\n        path = Path(base_path)\n        if path.exists():\n            # Find all .Scenes.csv files recursively\n            for csv_file in path.rglob(\"*.Scenes.csv\"):\n                # Get the corresponding video file name by removing .Scenes.csv\n                video_name = str(csv_file.name).replace(\".Scenes.csv\", \"\")\n                csv_files.append({\n                    \"csv_path\": str(csv_file),\n                    \"video_name\": video_name,\n                    \"drive\": os.path.splitdrive(str(csv_file))[0].upper(),\n                    \"directory\": str(csv_file.parent)\n                })\n        else:\n            print(f\"Warning: Path {base_path} does not exist\")\n\n    return pl.DataFrame(csv_files)\n\ndef get_processed_scenes():\n    tag_id = stash_raw_client.find_tag(\n        {\"name\": \"Scenes: PySceneDetect: Processed\"}\n    )[\"id\"]\n    scene_fragment = (\n        \"id title files { id basename path }\"\n        \" scene_markers { id primary_tag { id name }}\"\n    )\n    return stash_raw_client.find_scenes(\n        {\"tags\": {\"value\": [tag_id], \"modifier\": \"INCLUDES_ALL\"}},\n        fragment=scene_fragment,\n    )\n\nprint(\"Utility functions loaded and Stash client initialized\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Culture directory paths\n",
    "culture_paths = [\n",
    "    \"F:\\\\Culture\",\n",
    "    \"W:\\\\Culture\",\n",
    "    \"X:\\\\Culture\",\n",
    "    \"Y:\\\\Culture\",\n",
    "    \"Z:\\\\Culture\"\n",
    "]\n",
    "\n",
    "print(\"Scanning for CSV files in Culture directories...\")\n",
    "csv_files_df = find_csv_files(culture_paths)\n",
    "\n",
    "print(f\"Found {len(csv_files_df)} CSV files\")\n",
    "print(f\"CSV files by drive:\")\n",
    "csv_files_df.group_by(\"drive\").agg(pl.len().alias(\"count\")).sort(\"drive\")\n",
    "csv_files_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting processed scenes from Stash...\")\n",
    "processed_scenes_result = get_processed_scenes()\n",
    "\n",
    "print(f\"Found {len(processed_scenes_result)} processed scenes\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "processed_scenes_data = []\n",
    "for scene in processed_scenes_result:\n",
    "    for file in scene[\"files\"]:\n",
    "        # Get the basename without extension for comparison\n",
    "        basename_no_ext = Path(file[\"basename\"]).stem\n",
    "        processed_scenes_data.append({\n",
    "            \"scene_id\": scene[\"id\"],\n",
    "            \"title\": scene[\"title\"],\n",
    "            \"file_path\": file[\"path\"],\n",
    "            \"basename\": file[\"basename\"],\n",
    "            \"basename_no_ext\": basename_no_ext,\n",
    "            \"drive\": os.path.splitdrive(file[\"path\"])[0].upper()\n",
    "        })\n",
    "\n",
    "processed_scenes_df = pl.DataFrame(processed_scenes_data)\n",
    "\n",
    "print(f\"Processed scenes by drive:\")\n",
    "processed_scenes_df.group_by(\"drive\").agg(pl.len().alias(\"count\")).sort(\"drive\")\n",
    "processed_scenes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare CSV files with processed scenes\n",
    "print(\"Comparing CSV files with processed scenes...\")\n",
    "\n",
    "# Find CSV files that don't have corresponding processed scenes\n",
    "csv_without_processed = csv_files_df.join(\n",
    "    processed_scenes_df.select([\"basename_no_ext\", \"scene_id\"]),\n",
    "    left_on=\"video_name\",\n",
    "    right_on=\"basename_no_ext\",\n",
    "    how=\"left\"\n",
    ").filter(pl.col(\"scene_id\").is_null())\n",
    "\n",
    "print(f\"\\nCSV files without corresponding processed scenes: {len(csv_without_processed)}\")\n",
    "if len(csv_without_processed) > 0:\n",
    "    print(\"\\nCSV files without processed scenes by drive:\")\n",
    "    print(csv_without_processed.group_by(\"drive\").agg(pl.len().alias(\"count\")).sort(\"drive\"))\n",
    "\n",
    "csv_without_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find processed scenes that don't have corresponding CSV files\n",
    "processed_without_csv = processed_scenes_df.join(\n",
    "    csv_files_df.select([\"video_name\", \"csv_path\"]),\n",
    "    left_on=\"basename_no_ext\",\n",
    "    right_on=\"video_name\",\n",
    "    how=\"left\"\n",
    ").filter(pl.col(\"csv_path\").is_null())\n",
    "\n",
    "print(f\"\\nProcessed scenes without corresponding CSV files: {len(processed_without_csv)}\")\n",
    "if len(processed_without_csv) > 0:\n",
    "    print(\"\\nProcessed scenes without CSV files by drive:\")\n",
    "    print(processed_without_csv.group_by(\"drive\").agg(pl.len().alias(\"count\")).sort(\"drive\"))\n",
    "\n",
    "processed_without_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary analysis\n",
    "print(\"=== SUMMARY ===\")\n",
    "print(f\"Total CSV files found: {len(csv_files_df)}\")\n",
    "print(f\"Total processed scenes: {len(processed_scenes_df)}\")\n",
    "print(f\"CSV files without processed scenes: {len(csv_without_processed)}\")\n",
    "print(f\"Processed scenes without CSV files: {len(processed_without_csv)}\")\n",
    "\n",
    "# Check for exact matches\n",
    "exact_matches = csv_files_df.join(\n",
    "    processed_scenes_df.select([\"basename_no_ext\", \"scene_id\"]),\n",
    "    left_on=\"video_name\",\n",
    "    right_on=\"basename_no_ext\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(f\"Exact matches (CSV + Processed): {len(exact_matches)}\")\n",
    "print(f\"\\nDifference analysis:\")\n",
    "print(f\"CSV files - Processed scenes = {len(csv_files_df)} - {len(processed_scenes_df)} = {len(csv_files_df) - len(processed_scenes_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for potential filename mismatches\n",
    "print(\"\\n=== POTENTIAL FILENAME MISMATCHES ===\")\n",
    "\n",
    "# Get unique video names from CSV files\n",
    "csv_video_names = set(csv_files_df[\"video_name\"].to_list())\n",
    "processed_basenames = set(processed_scenes_df[\"basename_no_ext\"].to_list())\n",
    "\n",
    "# Find similar names that might be mismatches\n",
    "from difflib import get_close_matches\n",
    "\n",
    "\n",
    "if len(csv_without_processed) > 0:\n",
    "    print(\"\\nLooking for similar filenames for unmatched CSV files:\")\n",
    "    for row in csv_without_processed.iter_rows(named=True):\n",
    "        video_name = row[\"video_name\"]\n",
    "        # Find close matches in processed scenes\n",
    "        close_matches = get_close_matches(video_name, processed_basenames, n=3, cutoff=0.8)\n",
    "        if close_matches:\n",
    "            print(f\"\\nCSV: {video_name}\")\n",
    "            print(f\"  Possible matches: {close_matches}\")\n",
    "            print(f\"  CSV path: {row['csv_path']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the CSV video names by removing video extensions\n",
    "video_extensions = [\".mp4\", \".mkv\", \".avi\", \".wmv\", \".mov\"]\n",
    "\n",
    "csv_files_fixed = csv_files_df.with_columns([\n",
    "    pl.col(\"video_name\").map_elements(lambda x:\n",
    "        next((x.replace(ext, \"\") for ext in video_extensions if x.endswith(ext)), x)\n",
    "    ).alias(\"video_name_fixed\")\n",
    "])\n",
    "\n",
    "# Now redo the comparison with fixed names\n",
    "csv_without_processed_fixed = csv_files_fixed.join(\n",
    "    processed_scenes_df.select([\"basename_no_ext\", \"scene_id\"]),\n",
    "    left_on=\"video_name_fixed\",\n",
    "    right_on=\"basename_no_ext\",\n",
    "    how=\"left\"\n",
    ").filter(pl.col(\"scene_id\").is_null())\n",
    "\n",
    "processed_without_csv_fixed = processed_scenes_df.join(\n",
    "    csv_files_fixed.select([\"video_name_fixed\", \"csv_path\"]),\n",
    "    left_on=\"basename_no_ext\",\n",
    "    right_on=\"video_name_fixed\",\n",
    "    how=\"left\"\n",
    ").filter(pl.col(\"csv_path\").is_null())\n",
    "\n",
    "exact_matches_fixed = csv_files_fixed.join(\n",
    "    processed_scenes_df.select([\"basename_no_ext\", \"scene_id\"]),\n",
    "    left_on=\"video_name_fixed\",\n",
    "    right_on=\"basename_no_ext\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"=== FIXED SUMMARY ===\")\n",
    "print(f\"Total CSV files found: {len(csv_files_fixed)}\")\n",
    "print(f\"Total processed scenes: {len(processed_scenes_df)}\")\n",
    "print(f\"CSV files without processed scenes: {len(csv_without_processed_fixed)}\")\n",
    "print(f\"Processed scenes without CSV files: {len(processed_without_csv_fixed)}\")\n",
    "print(f\"Exact matches (CSV + Processed): {len(exact_matches_fixed)}\")\n",
    "\n",
    "print(f\"\\nThe missing CSV file(s):\")\n",
    "processed_without_csv_fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 2 CSV files that don't have processed scenes\n",
    "unprocessed_csv_files = csv_without_processed_fixed.select([\n",
    "    \"csv_path\",\n",
    "    \"video_name_fixed\",\n",
    "    \"drive\",\n",
    "    \"directory\"\n",
    "])\n",
    "\n",
    "print(f\"CSV files that need to be processed ({len(unprocessed_csv_files)}):\")\n",
    "unprocessed_csv_files\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}