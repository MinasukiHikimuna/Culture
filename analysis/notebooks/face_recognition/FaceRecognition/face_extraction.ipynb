{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from libraries.client_stashapp import StashAppClient, get_stashapp_client\n",
    "from libraries.FaceDatasetBuilder import FaceDatasetBuilder\n",
    "from libraries.scene_states import DatasetStructure, SceneState\n",
    "\n",
    "\n",
    "def get_stashdb_performer(performer):\n",
    "    \"\"\"Extract StashDB ID and name from performer data\"\"\"\n",
    "    for stash_id in performer[\"stashapp_performers_stash_ids\"]:\n",
    "        if stash_id[\"endpoint\"] == \"https://stashdb.org/graphql\":\n",
    "            return {\n",
    "                \"stash_id\": stash_id[\"stash_id\"],\n",
    "                \"name\": performer[\"stashapp_performers_name\"]\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Process a scene\n",
    "def process_scene(scene):\n",
    "    # Get performers with their StashDB IDs\n",
    "    performers = []\n",
    "    for performer in scene[\"stashapp_performers\"]:\n",
    "        stashdb_info = get_stashdb_performer(performer)\n",
    "        if stashdb_info:\n",
    "            performers.append(f\"{stashdb_info['stash_id']} - {stashdb_info['name']}\")\n",
    "\n",
    "    # Process the scene\n",
    "    if performers:\n",
    "        return builder.process_scene(\n",
    "            video_path=scene[\"stashapp_primary_file_path\"],\n",
    "            scene_id=scene[\"stashapp_stashdb_id\"],\n",
    "            performers=performers\n",
    "        )\n",
    "    return 0\n",
    "\n",
    "# Initialize builder\n",
    "builder = FaceDatasetBuilder()\n",
    "\n",
    "stash = get_stashapp_client()\n",
    "stash_client = StashAppClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_performers = stash_client.get_performers()\n",
    "performer = all_performers.filter(pl.col(\"stashapp_name\").str.contains(\"Tori Black\")).to_dicts()[0]\n",
    "favorite_performers = all_performers.filter(pl.col(\"stashapp_favorite\") == True)\n",
    "favorite_performers\n",
    "\n",
    "favorite_performer_ids = favorite_performers.select(pl.col(\"stashapp_id\")).to_series().to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_hidden_tag = stash.find_tag(\"Face Hidden\")[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stash.find_performers({\n",
    "    \"gender\": {\"value_list\": [\"MALE\"], \"modifier\": \"INCLUDES\" },\n",
    "    \"tags\": {\"value\": [], \"excludes\": [face_hidden_tag], \"modifier\": \"INCLUDES\" }\n",
    "}, { \"sort\": \"scenes_count\", \"direction\": \"DESC\", \"per_page\": 200 }, fragment=\"id name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_reality_tag = stash.find_tag(\"Virtual Reality\")[\"id\"]\n",
    "\n",
    "sample_scenes = stash_client.find_scenes({\n",
    "    \"performers\": {\"value\": favorite_performer_ids, \"excludes\": [], \"modifier\": \"INCLUDES\" },\n",
    "    \"tags\": {\"value\": [], \"excludes\": [virtual_reality_tag], \"modifier\": \"INCLUDES\" }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the processed scene IDs from file system\n",
    "dataset = DatasetStructure(\"H:\\\\Faces\\\\dataset\")\n",
    "\n",
    "# Get processed scenes from dataset info\n",
    "processed_scenes = {\n",
    "    scene_id for scene_id, state in dataset.info[\"processed_scenes\"].items()\n",
    "    if state in [SceneState.FACES_EXTRACTED.value, SceneState.VERIFIED.value]\n",
    "}\n",
    "\n",
    "# Filter out processed scenes from sample_scenes\n",
    "unprocessed_scenes = sample_scenes.filter(\n",
    "    ~pl.col(\"stashapp_stashdb_id\").is_in(processed_scenes)\n",
    ")\n",
    "\n",
    "print(f\"Total scenes: {len(sample_scenes)}\")\n",
    "print(f\"Already processed: {len(processed_scenes)}\")\n",
    "print(f\"Remaining to process: {len(unprocessed_scenes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per performer and create a DataFrame\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def get_performer_stats():\n",
    "    performer_dir = Path(\"H:\\\\Faces\\\\dataset\") / \"performers\" / \"deduplicated\"\n",
    "\n",
    "    # Collect performer statistics\n",
    "    stats = []\n",
    "    if performer_dir.exists():\n",
    "        for perf_dir in performer_dir.iterdir():\n",
    "            if perf_dir.is_dir():\n",
    "                # Split performer ID and name\n",
    "                try:\n",
    "                    performer_id, performer_name = perf_dir.name.split(\" - \", 1)\n",
    "                except ValueError:\n",
    "                    performer_id = perf_dir.name\n",
    "                    performer_name = \"Unknown\"\n",
    "\n",
    "                # Count images\n",
    "                image_count = len(list(perf_dir.glob(\"*.jpg\")))\n",
    "\n",
    "                if image_count > 0:  # Only include performers with images\n",
    "                    stats.append({\n",
    "                        \"performer_id\": performer_id,\n",
    "                        \"name\": performer_name,\n",
    "                        \"image_count\": image_count\n",
    "                    })\n",
    "\n",
    "    # Create DataFrame and sort by image count\n",
    "    df = pl.DataFrame(stats).sort(\"image_count\", descending=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Get and display performer statistics\n",
    "performer_stats = get_performer_stats()\n",
    "performer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "performers_by_scene_count = stash.find_performers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get a balanced batch of scenes to process\nMAX_SCENES = 512  # Total scenes to process\nMAX_PER_DRIVE = 1  # Maximum concurrent scenes per HDD\nSTORAGE_DRIVES = [\"X:\", \"Y:\", \"Z:\", \"W:\"]  # Available drives for processing\n\n# First, group all unprocessed scenes by drive\ndrive_scenes = {drive: [] for drive in STORAGE_DRIVES}  # Initialize all drives\n\n# Group scenes by drive\nfor scene in unprocessed_scenes.to_dicts():\n    performers = []\n    for performer in scene[\"stashapp_performers\"]:\n        stashdb_info = get_stashdb_performer(performer)\n        if stashdb_info:\n            performers.append(f\"{stashdb_info['stash_id']} - {stashdb_info['name']}\")\n\n    if performers:\n        video_path = scene[\"stashapp_primary_file_path\"]\n        drive = os.path.splitdrive(video_path)[0].upper()\n\n        if drive in STORAGE_DRIVES:  # Only process from our storage drives\n            scene[\"video_path\"] = video_path\n            scene[\"performers\"] = performers\n            drive_scenes[drive].append(scene)\n\n# Simple round-robin selection\nscenes_to_process = []\nfor i in range(MAX_SCENES):\n    drive = STORAGE_DRIVES[i % len(STORAGE_DRIVES)]\n    if drive_scenes[drive]:  # If this drive has any scenes left\n        scenes_to_process.append(drive_scenes[drive].pop(0))\n\n# Print scene distribution\nprint(\"Scenes per drive:\")\ndrive_counts = {}\nfor scene in scenes_to_process:\n    drive = os.path.splitdrive(scene[\"video_path\"])[0].upper()\n    drive_counts[drive] = drive_counts.get(drive, 0) + 1\n\nfor drive in STORAGE_DRIVES:\n    print(f\"{drive}: {drive_counts.get(drive, 0)} scenes\")\n\n# Create JSON files in pending directory\npending_dir = Path(\"H:\\\\Faces\\\\dataset\") / \"scenes\" / SceneState.PENDING.value\npending_dir.mkdir(parents=True, exist_ok=True)\n\nfor scene in scenes_to_process:\n    scene_id = scene[\"stashapp_stashdb_id\"]\n    scene_data = {\n        \"video_path\": scene[\"video_path\"],\n        \"performers\": scene[\"performers\"]\n    }\n\n    json_path = pending_dir / f\"{scene_id}.json\"\n    with open(json_path, \"w\") as f:\n        json.dump(scene_data, f, indent=2)\n\nprint(f\"\\nCreated {len(scenes_to_process)} JSON files in {pending_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversifying selected images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install imagehash scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import shutil\n\nimport imagehash\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.cluster import KMeans\n\n\ndef deduplicate_faces(face_dir, output_dir, max_faces=100):\n    \"\"\"\n    Cluster similar faces and keep the most representative ones using perceptual hashing.\n    Saves results to a separate directory instead of moving original files.\n    \"\"\"\n    # Calculate perceptual hashes for all images\n    hashes = []\n    paths = []\n    for img_path in Path(face_dir).iterdir():\n        if img_path.suffix == \".jpg\":\n            full_path = str(img_path)\n            try:\n                # Use both average and perceptual hash for better similarity detection\n                img = Image.open(full_path)\n                avg_hash = imagehash.average_hash(img)\n                phash = imagehash.phash(img)\n                # Convert hash to binary array (each bit becomes a feature)\n                hash_array = np.array([bit for bit in bin(int(str(avg_hash), 16))[2:].zfill(64)] +\n                                    [bit for bit in bin(int(str(phash), 16))[2:].zfill(64)], dtype=int)\n                hashes.append(hash_array)\n                paths.append(full_path)\n            except Exception as e:\n                print(f\"Error processing {img_path.name}: {e}\")\n\n    if not hashes:\n        return []\n\n    # Convert list of hash arrays to 2D numpy array\n    hash_vectors = np.array(hashes)\n\n    # Cluster similar images\n    n_clusters = min(max_faces, len(paths))\n    kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n    clusters = kmeans.fit_predict(hash_vectors)\n\n    # Keep images closest to cluster centers\n    kept_images = []\n    for i in range(n_clusters):\n        cluster_indices = np.where(clusters == i)[0]\n        if len(cluster_indices) > 0:\n            # Find image closest to cluster center\n            distances = np.linalg.norm(\n                hash_vectors[cluster_indices] - kmeans.cluster_centers_[i],\n                axis=1\n            )\n            closest_idx = cluster_indices[np.argmin(distances)]\n            kept_images.append(paths[closest_idx])\n\n    return kept_images\n\n# Set up directories\nbase_dir = Path(\"H:\\\\Faces\\\\dataset\")\nsource_dir = base_dir / \"performers\" / \"verified\"\noutput_dir = base_dir / \"performers\" / \"deduplicated\"\n\n# Create output directory\noutput_dir.mkdir(parents=True, exist_ok=True)\n\nprint(\"\\nDeduplication Summary:\")\nprint(\"-\" * 50)\n\nif source_dir.exists():\n    for perf_dir in source_dir.iterdir():\n        if perf_dir.is_dir():\n            print(f\"\\nProcessing {perf_dir.name}\")\n\n            # Create performer directory in output\n            perf_output_dir = output_dir / perf_dir.name\n            perf_output_dir.mkdir(exist_ok=True)\n\n            # Count images\n            original_count = len(list(perf_dir.glob(\"*.jpg\")))\n\n            if original_count > 0:\n                # Get most representative images\n                kept_images = deduplicate_faces(perf_dir, perf_output_dir,\n                                             max_faces=min(100, original_count))\n\n                # Copy selected images to output directory\n                for img_path in kept_images:\n                    shutil.copy2(img_path, perf_output_dir)\n\n                final_count = len(kept_images)\n                print(f\"Original: {original_count}\")\n                print(f\"Kept: {final_count}\")\n                if original_count > final_count:\n                    print(f\"Reduction: {((original_count - final_count) / original_count * 100):.1f}%\")\n\n# Print warning for performers with few images\nprint(\"\\nPerformers with fewer than 20 images:\")\nprint(\"-\" * 50)\nfor perf_dir in source_dir.iterdir():\n    if perf_dir.is_dir():\n        image_count = len(list(perf_dir.glob(\"*.jpg\")))\n        if image_count < 20:\n            print(f\"{perf_dir.name}: {image_count} images\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}