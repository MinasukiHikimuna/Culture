{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ab5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import polars as pl\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath(\"\")))\n",
    "\n",
    "from libraries.client_stashapp import get_stashapp_client, StashAppClient\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from NZB.search import NZBSearch\n",
    "from NZB.sabnzbd import SABnzbdClient\n",
    "\n",
    "searcher = NZBSearch()\n",
    "\n",
    "\n",
    "def format_str_iso_date_as_yy_mm_dd(iso_date_str):\n",
    "    from datetime import datetime\n",
    "\n",
    "    parsed_date = datetime.strptime(iso_date_str, \"%Y-%m-%d\")\n",
    "    return format_iso_date_as_yy_mm_dd(parsed_date)\n",
    "\n",
    "\n",
    "def format_iso_date_as_yy_mm_dd(iso_date):\n",
    "    return iso_date.strftime(\"%y %m %d\")\n",
    "\n",
    "\n",
    "def format_studio_name(studio_name):\n",
    "    return studio_name.replace(\" \", \"\").replace(\"-\", \"\")\n",
    "\n",
    "\n",
    "stash = get_stashapp_client(\"MISSING_SDB_\")\n",
    "stash_client = StashAppClient(\"MISSING_SDB_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a67208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StashDB\n",
    "from libraries.StashDbClient import StashDbClient\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "stashbox_client = StashDbClient(\n",
    "    os.getenv(\"STASHDB_ENDPOINT\"),\n",
    "    os.getenv(\"STASHDB_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b185c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find by studio\n",
    "studio_id = stash.find_studio(\"DarkX\")[\"id\"]\n",
    "\n",
    "target_scenes: pl.DataFrame = pl.DataFrame(\n",
    "    stash.find_scenes(\n",
    "        {\"studios\": {\"value\": [studio_id], \"modifier\": \"INCLUDES\"}},\n",
    "        fragment=\"id title date details studio { id name } performers { id name }\",\n",
    "    )\n",
    ")\n",
    "target_scenes = target_scenes.sort(by=[\"studio\", \"date\"])\n",
    "target_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5a572",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Find by performer\n",
    "performer_id = stash.find_performer(\"Stacy Cruz\")[\"id\"]\n",
    "\n",
    "target_scenes: pl.DataFrame = pl.DataFrame(\n",
    "    stash.find_scenes(\n",
    "        {\"performers\": {\"value\": [performer_id], \"modifier\": \"INCLUDES\"}},\n",
    "        fragment=\"id title date details studio { id name } performers { id name }\",\n",
    "    )\n",
    ")\n",
    "target_scenes = target_scenes.sort(by=[\"studio\", \"date\"])\n",
    "# target_scenes = target_scenes.filter(pl.col(\"studio\").struct.field(\"name\").str.contains(\"Passion HD\"))\n",
    "target_scenes = target_scenes.slice(0, 10)\n",
    "target_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693eaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find by performer and studio\n",
    "performer_id = stash.find_performer(\"Pearl\")[\"id\"]\n",
    "studio_id = stash.find_studio(\"Viv Thomas\")[\"id\"]\n",
    "\n",
    "target_scenes: pl.DataFrame = pl.DataFrame(\n",
    "    stash.find_scenes(\n",
    "        {\n",
    "            \"performers\": {\"value\": [performer_id], \"modifier\": \"INCLUDES\"},\n",
    "            \"studios\": {\"value\": [studio_id], \"modifier\": \"INCLUDES\"},\n",
    "        },\n",
    "        fragment=\"id title date details studio { id name } performers { id name }\",\n",
    "    )\n",
    ")\n",
    "target_scenes = target_scenes.sort(by=[\"studio\", \"date\"])\n",
    "target_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_queries(stashdb_target_scene, stashdb_primary_performers):\n",
    "    \"\"\"Generate a list of search queries for a scene, from most to least specific\"\"\"\n",
    "    queries = []\n",
    "\n",
    "    # Get performer names (using alias if available)\n",
    "    performer_names = [\n",
    "        performer[\"as\"] or performer[\"performer\"][\"name\"]\n",
    "        for performer in stashdb_primary_performers\n",
    "    ]\n",
    "\n",
    "    # Format date\n",
    "    date_str = format_iso_date_as_yy_mm_dd(stashdb_target_scene[\"date\"])\n",
    "    studio_name = format_studio_name(stashdb_target_scene[\"studio\"][\"name\"])\n",
    "\n",
    "    # Most specific: studio + performer + date\n",
    "    if performer_names:\n",
    "        queries.append(f'{studio_name} {performer_names[0]} \"{date_str}\"')\n",
    "\n",
    "    # Next: first performer + date\n",
    "    if performer_names:\n",
    "        queries.append(f'{performer_names[0]} \"{date_str}\"')\n",
    "\n",
    "    # Next: studio + date (less specific, may return multiple scenes)\n",
    "    queries.append(f'{studio_name} \"{date_str}\"')\n",
    "\n",
    "    # Finally: studio + first performer (no date)\n",
    "    if performer_names:\n",
    "        queries.append(f\"{studio_name} {performer_names[0]}\")\n",
    "\n",
    "    return queries\n",
    "\n",
    "\n",
    "# Get search queries for each scene\n",
    "search_queries_list = []\n",
    "scene_info_list = []  # Store scene info for later mapping\n",
    "\n",
    "for scene_dict in target_scenes.to_dicts():\n",
    "    # Get StashDB data for scene\n",
    "    stashapp_target_scene = stash.find_scene(\n",
    "        scene_dict[\"id\"],\n",
    "        fragment=\"id title details urls date performers { id name stash_ids { stash_id endpoint } } studio { id name } stash_ids { stash_id endpoint }\",\n",
    "    )\n",
    "\n",
    "    # Get StashDB ID\n",
    "    stashdb_ids = [\n",
    "        stash_id[\"stash_id\"]\n",
    "        for stash_id in stashapp_target_scene[\"stash_ids\"]\n",
    "        if stash_id[\"endpoint\"] == \"https://stashdb.org/graphql\"\n",
    "    ]\n",
    "    if not stashdb_ids:\n",
    "        continue\n",
    "\n",
    "    # Get StashDB scene data\n",
    "    stashdb_scenes = stashbox_client.query_scenes([stashdb_ids[0]])\n",
    "    if stashdb_scenes.is_empty():\n",
    "        continue\n",
    "    stashdb_target_scene = stashdb_scenes.to_dicts()[0]\n",
    "\n",
    "    # Get primary performers\n",
    "    primary_performer_ids = [\n",
    "        stash_id[\"stash_id\"]\n",
    "        for performer in stashapp_target_scene[\"performers\"]\n",
    "        for stash_id in performer[\"stash_ids\"]\n",
    "        if stash_id[\"endpoint\"] == \"https://stashdb.org/graphql\"\n",
    "    ]\n",
    "\n",
    "    stashdb_primary_performers = [\n",
    "        performer\n",
    "        for performer in stashdb_target_scene[\"performers\"]\n",
    "        if performer[\"performer\"][\"id\"] in primary_performer_ids\n",
    "    ]\n",
    "\n",
    "    # Generate queries for this scene\n",
    "    scene_queries = generate_search_queries(\n",
    "        stashdb_target_scene, stashdb_primary_performers\n",
    "    )\n",
    "    search_queries_list.append(scene_queries)\n",
    "\n",
    "    # Store scene info\n",
    "    scene_info = {\n",
    "        \"stashapp_id\": stashapp_target_scene[\"id\"],\n",
    "        \"stashapp_title\": stashapp_target_scene[\"title\"],\n",
    "        \"stashdb_id\": stashdb_ids[0],\n",
    "        \"stashdb_title\": stashdb_target_scene[\"title\"],\n",
    "        \"studio\": stashdb_target_scene[\"studio\"][\"name\"],\n",
    "        \"date\": stashdb_target_scene[\"date\"],\n",
    "        \"performers\": [p[\"performer\"][\"name\"] for p in stashdb_primary_performers],\n",
    "        \"primary_query\": scene_queries[0],  # Store primary query to use as join key\n",
    "    }\n",
    "    scene_info_list.append(scene_info)\n",
    "\n",
    "# Create DataFrame with scene info\n",
    "scenes_df = pl.DataFrame(scene_info_list)\n",
    "\n",
    "# Perform the search\n",
    "results = searcher.search(search_queries_list)\n",
    "\n",
    "# Join scene info with search results\n",
    "results_with_scenes = results.join(\n",
    "    scenes_df, left_on=\"primary_query\", right_on=\"primary_query\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Sort results to show best matches first for each scene\n",
    "results_with_scenes = results_with_scenes.sort(\n",
    "    [\n",
    "        \"stashapp_id\",  # Group by scene\n",
    "        \"is_best_match\",  # Best matches first\n",
    "        \"size\",  # Larger files first\n",
    "    ],\n",
    "    descending=[False, True, True],\n",
    ")\n",
    "\n",
    "results_with_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = results_with_scenes.filter(pl.col(\"is_best_match\")).unique(\n",
    "    [\"link\", \"title\"]\n",
    ")\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad5970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sab = SABnzbdClient()\n",
    "\n",
    "for result in best_results.iter_rows(named=True):\n",
    "    # Add the download\n",
    "    nzb_result = sab.add_nzb_url(result[\"link\"], result[\"title\"])\n",
    "\n",
    "# if nzb_result['status']:\n",
    "#     if 'nzo_id' in nzb_result:\n",
    "#         # Wait for download to complete\n",
    "#         download_result = sab.wait_for_completion(nzb_result['nzo_id'])\n",
    "#         if download_result['status'] == 'completed':\n",
    "#             print(f\"Download completed! File saved to: {download_result['path']}\")\n",
    "#         else:\n",
    "#             print(f\"Download failed: {download_result.get('error', 'Unknown error')}\")\n",
    "#     else:\n",
    "#         print(f\"Added to SABnzbd but couldn't get job ID: {nzb_result.get('error')}\")\n",
    "# else:\n",
    "#     print(f\"Failed to add to SABnzbd: {nzb_result.get('error')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = \"hersexdebut sata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b83706",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "results = searcher.search(search_query)\n",
    "if results.is_empty():\n",
    "    results = searcher.search(performer_search_query)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result = results.to_dicts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sab.add_nzb_url(first_result[\"link\"], first_result[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89395deb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get all files in download directory\n",
    "files = os.listdir(download_result[\"path\"])\n",
    "\n",
    "# Get full paths and sizes\n",
    "file_info = []\n",
    "for f in files:\n",
    "    full_path = os.path.join(download_result[\"path\"], f)\n",
    "    if os.path.isfile(full_path):\n",
    "        size = os.path.getsize(full_path)\n",
    "        file_info.append((full_path, size))\n",
    "\n",
    "# Sort by size descending\n",
    "file_info.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get largest video file\n",
    "video_extensions = {\".mp4\", \".mkv\", \".avi\", \".wmv\", \".mov\"}\n",
    "for filepath, size in file_info:\n",
    "    ext = os.path.splitext(filepath)[1].lower()\n",
    "    if ext in video_extensions:\n",
    "        converted_filepath = filepath\n",
    "        break\n",
    "else:\n",
    "    raise Exception(\"No video file found in download directory\")\n",
    "\n",
    "print(f\"Using video file: {converted_filepath} ({size/1024/1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "process = subprocess.run(\n",
    "    [\n",
    "        \"C:\\\\Tools\\\\videohashes-windows-amd64.exe\",\n",
    "        \"-json\",\n",
    "        converted_filepath,\n",
    "    ],\n",
    "    capture_output=True,  # Captures both stdout and stderr\n",
    "    text=True,  # Returns strings instead of bytes\n",
    ")\n",
    "assert process.returncode == 0, f\"Failed to run videohashes: {process.stderr}\"\n",
    "videohashes_data = json.loads(process.stdout)\n",
    "videohashes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02032322",
   "metadata": {},
   "outputs": [],
   "source": [
    "videohashes_data[\"phash\"] in [\n",
    "    fingerprint[\"hash\"]\n",
    "    for fingerprint in target_scene[\"fingerprints\"]\n",
    "    if fingerprint[\"algorithm\"] == \"PHASH\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "CultureDataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
