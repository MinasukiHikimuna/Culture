{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e965ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "# Import StashApp client\n",
    "from libraries.client_stashapp import StashAppClient, get_stashapp_client\n",
    "\n",
    "\n",
    "# Initialize clients\n",
    "stash_client = StashAppClient()\n",
    "stash_raw_client = get_stashapp_client()\n",
    "\n",
    "# Define paths to scan\n",
    "PATHS = [\n",
    "    r\"W:\\Culture\\Photos\",\n",
    "    r\"F:\\Culture\\Staging\",\n",
    "    r\"F:\\Culture\\Videos\",\n",
    "    r\"W:\\Culture\\Videos\",\n",
    "    r\"X:\\Culture\\Videos\",\n",
    "    r\"Y:\\Culture\\Videos\",\n",
    "    r\"Z:\\Culture\\Videos\",\n",
    "]\n",
    "\n",
    "# Define Culture Extractor endpoint\n",
    "CULTURE_EXTRACTOR_ENDPOINT = \"https://culture.extractor/graphql\"\n",
    "\n",
    "\n",
    "def is_valid_uuid(uuid_str: str) -> bool:\n",
    "    \"\"\"Check if a string is a valid UUID.\"\"\"\n",
    "    try:\n",
    "        uuid_obj = uuid.UUID(uuid_str)\n",
    "        return str(uuid_obj) == uuid_str\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_uuid_from_filename(filename: str) -> str | None:\n",
    "    \"\"\"Extract UUID from filename if it exists.\"\"\"\n",
    "    # Match UUID pattern at the end of filename before extension\n",
    "    match = re.search(\n",
    "        r\"([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})\\.\", filename\n",
    "    )\n",
    "    if match and is_valid_uuid(match.group(1)):\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_existing_ce_stash_id(existing_stash_ids: List[Dict]) -> str | None:\n",
    "    \"\"\"Get existing Culture Extractor stash_id if it exists.\"\"\"\n",
    "    for sid in existing_stash_ids:\n",
    "        if sid.get(\"endpoint\") == CULTURE_EXTRACTOR_ENDPOINT:\n",
    "            return sid.get(\"stash_id\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def merge_stash_ids(\n",
    "    existing_stash_ids: List[Dict], new_endpoint: str, new_stash_id: str\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Merge new stash_id with existing ones, preserving other endpoints.\"\"\"\n",
    "    # Start with existing stash_ids, filtering out any existing culture.extractor entries\n",
    "    merged = [sid for sid in existing_stash_ids if sid.get(\"endpoint\") != new_endpoint]\n",
    "\n",
    "    # Add the new culture.extractor stash_id\n",
    "    merged.append({\"endpoint\": new_endpoint, \"stash_id\": new_stash_id})\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all scenes with their files and existing stash_ids\n",
    "scenes = stash_raw_client.find_scenes(\n",
    "    fragment=\"\"\"\n",
    "    id\n",
    "    title\n",
    "    stash_ids {\n",
    "        endpoint\n",
    "        stash_id\n",
    "    }\n",
    "    files {\n",
    "        id\n",
    "        basename\n",
    "        path\n",
    "    }\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Process scenes and files to extract UUIDs from filenames\n",
    "results = []\n",
    "\n",
    "for scene in scenes:\n",
    "    scene_id = scene.get(\"id\")\n",
    "    scene_title = scene.get(\"title\")\n",
    "    existing_stash_ids = scene.get(\"stash_ids\", [])\n",
    "    files = scene.get(\"files\", [])\n",
    "    for file in files:\n",
    "        file_basename = file.get(\"basename\")\n",
    "        file_path = file.get(\"path\")\n",
    "        # Only consider files in the specified PATHS\n",
    "        if not any(str(file_path).startswith(p) for p in PATHS):\n",
    "            continue\n",
    "        ce_uuid = extract_uuid_from_filename(file_basename)\n",
    "        results.append(\n",
    "            {\n",
    "                \"scene_id\": scene_id,\n",
    "                \"scene_title\": scene_title,\n",
    "                \"file_basename\": file_basename,\n",
    "                \"file_path\": file_path,\n",
    "                \"ce_uuid\": ce_uuid,\n",
    "                \"existing_stash_ids\": existing_stash_ids,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Ensure all dicts have the same keys\n",
    "all_keys = {k for d in results for k in d.keys()}\n",
    "for d in results:\n",
    "    for k in all_keys:\n",
    "        if k not in d:\n",
    "            d[k] = None\n",
    "\n",
    "# Ensure all ce_uuid values are str or None\n",
    "for d in results:\n",
    "    if d[\"ce_uuid\"] is not None:\n",
    "        d[\"ce_uuid\"] = str(d[\"ce_uuid\"])\n",
    "    else:\n",
    "        d[\"ce_uuid\"] = None\n",
    "\n",
    "# Build DataFrame with explicit schema override for ce_uuid column\n",
    "files_df = pl.DataFrame(\n",
    "    results, schema_overrides={\"ce_uuid\": pl.Utf8}, infer_schema_length=1000\n",
    ")\n",
    "\n",
    "# Filter to only files with a found UUID\n",
    "files_with_uuid_df = files_df.filter(pl.col(\"ce_uuid\").is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b574b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out scenes that already have the matching Culture Extractor stash ID\n",
    "scenes_to_update = []\n",
    "scenes_already_set = []\n",
    "\n",
    "for row in files_with_uuid_df.iter_rows(named=True):\n",
    "    existing_stash_ids = row[\"existing_stash_ids\"] or []\n",
    "    existing_ce_stash_id = get_existing_ce_stash_id(existing_stash_ids)\n",
    "\n",
    "    # Check if the same UUID is already set\n",
    "    if existing_ce_stash_id == row[\"ce_uuid\"]:\n",
    "        scenes_already_set.append(row)\n",
    "    else:\n",
    "        scenes_to_update.append(row)\n",
    "\n",
    "# Create DataFrames for verification\n",
    "scenes_to_update_df = (\n",
    "    pl.DataFrame(scenes_to_update) if scenes_to_update else pl.DataFrame()\n",
    ")\n",
    "scenes_already_set_df = (\n",
    "    pl.DataFrame(scenes_already_set) if scenes_already_set else pl.DataFrame()\n",
    ")\n",
    "\n",
    "print(f\"Total scenes with UUIDs found: {len(files_with_uuid_df)}\")\n",
    "print(f\"Scenes that need updating: {len(scenes_to_update_df)}\")\n",
    "print(f\"Scenes already set (skipped): {len(scenes_already_set_df)}\")\n",
    "\n",
    "if len(scenes_already_set_df) > 0:\n",
    "    print(\"\\nScenes already set with matching Culture Extractor stash ID:\")\n",
    "    print(\n",
    "        scenes_already_set_df.select(\n",
    "            [\"scene_id\", \"scene_title\", \"file_basename\", \"ce_uuid\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(\"\\nScenes to be updated:\")\n",
    "scenes_to_update_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d91c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply step: Update scenes with extracted UUIDs as stash_ids (preserving existing stash_ids)\n",
    "update_results = []\n",
    "\n",
    "for row in scenes_to_update_df.iter_rows(named=True):\n",
    "    scene_id = row[\"scene_id\"]\n",
    "    ce_uuid = row[\"ce_uuid\"]\n",
    "    scene_title = row[\"scene_title\"]\n",
    "    file_basename = row[\"file_basename\"]\n",
    "    existing_stash_ids = row[\"existing_stash_ids\"] or []\n",
    "\n",
    "    try:\n",
    "        # Merge stash_ids preserving existing ones\n",
    "        merged_stash_ids = merge_stash_ids(\n",
    "            existing_stash_ids, CULTURE_EXTRACTOR_ENDPOINT, ce_uuid\n",
    "        )\n",
    "\n",
    "        # Update the scene with merged stash_ids\n",
    "        result = stash_raw_client.update_scene(\n",
    "            {\n",
    "                \"id\": scene_id,\n",
    "                \"stash_ids\": merged_stash_ids,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        update_results.append(\n",
    "            {\n",
    "                \"scene_id\": scene_id,\n",
    "                \"scene_title\": scene_title,\n",
    "                \"file_basename\": file_basename,\n",
    "                \"ce_uuid\": ce_uuid,\n",
    "                \"status\": \"success\",\n",
    "                \"error\": None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"✓ Updated scene {scene_id} ({scene_title}) with UUID {ce_uuid} (preserved {len(existing_stash_ids)} existing stash_ids)\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        update_results.append(\n",
    "            {\n",
    "                \"scene_id\": scene_id,\n",
    "                \"scene_title\": scene_title,\n",
    "                \"file_basename\": file_basename,\n",
    "                \"ce_uuid\": ce_uuid,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"✗ Failed to update scene {scene_id} ({scene_title}): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of apply step results\n",
    "if update_results:\n",
    "    update_results_df = pl.DataFrame(update_results)\n",
    "    print(f\"Total scenes processed: {len(update_results_df)}\")\n",
    "    print(\n",
    "        f\"Successful updates: {len(update_results_df.filter(pl.col('status') == 'success'))}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Failed updates: {len(update_results_df.filter(pl.col('status') == 'error'))}\"\n",
    "    )\n",
    "\n",
    "    # Show any errors\n",
    "    errors_df = update_results_df.filter(pl.col(\"status\") == \"error\")\n",
    "    if len(errors_df) > 0:\n",
    "        print(\"\\nErrors encountered:\")\n",
    "        errors_df\n",
    "\n",
    "    # Show successful updates\n",
    "    success_df = update_results_df.filter(pl.col(\"status\") == \"success\")\n",
    "    success_df\n",
    "else:\n",
    "    print(\"No scenes needed updating.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "CultureDataAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
