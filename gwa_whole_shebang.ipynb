{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "reddit = praw.Reddit(client_id = os.getenv(\"REDDIT_CLIENT_ID\"), client_secret = os.getenv(\"REDDIT_CLIENT_SECRET\"), password = os.getenv(\"REDDIT_CLIENT_PASSWORD\"), user_agent = os.getenv(\"REDDIT_CLIENT_USER_AGENT\"), username = os.getenv(\"REDDIT_CLIENT_USERNAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stash app client\n",
    "import dotenv\n",
    "\n",
    "from libraries.client_stashapp import get_stashapp_client\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "stash = get_stashapp_client(\"AURAL_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Beautiful Soup to find all external URLs in the HTML\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import re\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "link_source_enum = {\"unknown\": 0, \"audio\": 1, \"script\": 2, \"reddit_script\": 3}\n",
    "file_type_enum = {\"audio\": 1, \"script\": 2}\n",
    "\n",
    "save_path = \"F:\\\\GWA\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "\n",
    "def download_reddit_post(url):\n",
    "    files = []\n",
    "    \n",
    "    post_id = extract_post_id(url)\n",
    "    submission = reddit.submission(id=post_id)\n",
    "    post_data = extract_post_data(submission)\n",
    "\n",
    "    audio_links = [link for link in post_data[\"links\"] if link[\"type\"] == link_source_enum[\"audio\"]]\n",
    "\n",
    "    for audio_link in audio_links:\n",
    "        if \"soundgasm.net\" in audio_link[\"url\"]:\n",
    "            (audio_filepath, audio_data) = download_soundgasm_audio(post_data, audio_link[\"url\"])\n",
    "            files.append({ \"type\": file_type_enum[\"audio\"], \"filepath\": audio_filepath, \"data\": audio_data })\n",
    "\n",
    "    script_links = [link for link in post_data[\"links\"] if link[\"type\"] == link_source_enum[\"script\"]]\n",
    "\n",
    "    for script_link in script_links:\n",
    "        if \"scriptbin.works\" in script_link[\"url\"]:\n",
    "            (script_filepath, script_data) = download_scriptbin_script(post_data, script_link[\"url\"])\n",
    "            files.append({ \"type\": file_type_enum[\"script\"], \"filepath\": script_filepath, \"data\": script_data })\n",
    "    \n",
    "    json_data = {\n",
    "        \"url\": url,\n",
    "        \"reddit\": post_data,\n",
    "        \"files\": files\n",
    "    }\n",
    "\n",
    "    # Create filename using post metadata\n",
    "    filename = post_data[\"base_filename\"] + \".json\"\n",
    "\n",
    "    # Save to JSON file\n",
    "    filepath = os.path.join(save_path, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "def extract_post_id(url):\n",
    "    # Match patterns like /comments/xxxxx/ or /xxxxx\n",
    "    patterns = [\n",
    "        r\"/comments/([a-z0-9]+)/?\",\n",
    "        r\"reddit\\.com/r/[^/]+/([a-z0-9]+)/?\",\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "\n",
    "    raise ValueError(\"Could not extract post ID from URL\")\n",
    "\n",
    "\n",
    "def extract_post_data(post):\n",
    "    post_data = {\n",
    "        \"base_filename\": format_filename(post.author.name, post.created_utc, post.id),\n",
    "        \"title\": post.title,\n",
    "        \"author\": {\n",
    "            \"name\": post.author.name if post.author else \"[deleted]\",\n",
    "            \"fullname\": post.author.fullname if post.author else \"[deleted]\",\n",
    "            \"flair\": post.author_flair_text,\n",
    "        },\n",
    "        \"url\": post.url,\n",
    "        \"created_utc\": post.created_utc,\n",
    "        \"id\": post.id,\n",
    "        \"permalink\": f\"https://reddit.com{post.permalink}\",\n",
    "        \"score\": post.score,\n",
    "        \"subreddit\": post.subreddit.display_name,\n",
    "        \"selftext\": post.selftext,\n",
    "        \"selftext_html\": post.selftext_html,\n",
    "        \"links\": extract_post_links(post.selftext_html),\n",
    "    }\n",
    "    \n",
    "    reddit_script_links = [link for link in post_data[\"links\"] if link[\"type\"] == link_source_enum[\"reddit_script\"]]\n",
    "    if len(reddit_script_links) == 1:\n",
    "        reddit_script_id = extract_post_id(reddit_script_links[0][\"url\"])\n",
    "        reddit_script_data = extract_reddit_script_data(reddit_script_id)\n",
    "        \n",
    "        for script_link in reddit_script_data[\"links\"]:\n",
    "            if script_link[\"type\"] == link_source_enum[\"script\"]:\n",
    "                post_data[\"links\"].append(script_link)\n",
    "        \n",
    "        post_data[\"reddit_script\"] = reddit_script_data\n",
    "    elif len(reddit_script_links) > 1:\n",
    "        raise ValueError(\"Multiple Reddit script links found in post\")\n",
    "    \n",
    "    return post_data\n",
    "\n",
    "def extract_reddit_script_data(post_id):\n",
    "    submission = reddit.submission(id=post_id)\n",
    "    script_post_data = {\n",
    "        \"title\": submission.title,\n",
    "        \"author\": {\n",
    "            \"name\": submission.author.name if submission.author else \"[deleted]\",\n",
    "            \"fullname\": submission.author.fullname if submission.author else \"[deleted]\",\n",
    "            \"flair\": submission.author_flair_text,\n",
    "        },\n",
    "        \"url\": submission.url,\n",
    "        \"created_utc\": submission.created_utc,\n",
    "        \"id\": submission.id,\n",
    "        \"permalink\": f\"https://reddit.com{submission.permalink}\",\n",
    "        \"score\": submission.score,\n",
    "        \"subreddit\": submission.subreddit.display_name,\n",
    "        \"selftext\": submission.selftext,\n",
    "        \"selftext_html\": submission.selftext_html,\n",
    "        \"links\": extract_post_links(submission.selftext_html),\n",
    "    }\n",
    "    return script_post_data\n",
    "\n",
    "def extract_post_links(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = [\n",
    "        {\n",
    "            \"url\": link.get(\"href\"),\n",
    "            \"text\": link.text,\n",
    "            \"type\": determine_link_type(link.text, link.get(\"href\")),\n",
    "        }\n",
    "        for link in soup.find_all(\"a\", href=True)\n",
    "    ]\n",
    "    return links\n",
    "\n",
    "def determine_link_type(text, url):\n",
    "    if \"SOUNDGASM\" in url.upper():\n",
    "        return link_source_enum[\"audio\"]\n",
    "    elif \"SCRIPTBIN\" in url.upper():\n",
    "        return link_source_enum[\"script\"]\n",
    "    elif \"SCRIPT\" in text.upper():\n",
    "        return link_source_enum[\"reddit_script\"]\n",
    "    else:\n",
    "        return link_source_enum[\"unknown\"]\n",
    "\n",
    "def format_filename(author, created_utc, post_id):\n",
    "    # Convert UTC timestamp to datetime\n",
    "    date_str = datetime.fromtimestamp(created_utc).strftime(\"%Y-%m-%d\")\n",
    "    # Create safe filename\n",
    "    author = \"\".join(c for c in author if c.isalnum() or c in (\"-\", \"_\"))\n",
    "    return f\"{author}_{date_str}_{post_id}\"\n",
    "\n",
    "def determine_performer_gender(author_flair):\n",
    "    if \"FEMALE\" in author_flair.upper():\n",
    "        return \"FEMALE\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown gender for author flair: {author_flair}\")\n",
    "\n",
    "def convert_audio_to_video(input_file, output_file):\n",
    "    ffmpeg_path = \"ffmpeg\"\n",
    "    command = [\n",
    "        ffmpeg_path,\n",
    "        \"-loop\", \"1\",\n",
    "        \"-i\", \"X:\\\\gwa.png\",\n",
    "        \"-i\", input_file,\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-c:a\", \"copy\",\n",
    "        \"-shortest\",\n",
    "        \"-vf\", \"scale=256:256\",\n",
    "        output_file\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "def download_soundgasm_audio(post_data, url):\n",
    "    if not \"soundgasm.net\" in url:\n",
    "        raise ValueError(f\"URL is not a Soundgasm URL: {url}\")\n",
    "    \n",
    "    # Get and parse the soundgasm page\n",
    "    response = requests.get(url)\n",
    "    soundgasm_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "    # Find the audio source element\n",
    "    media_url_match = re.search(r'(https://media\\.soundgasm\\.net/sounds/[a-zA-Z0-9]+\\.(?:m4a|mp3))', response.text)\n",
    "    media_url = media_url_match.group(1) if media_url_match else None\n",
    "    \n",
    "    if not media_url:\n",
    "        raise ValueError(f\"No audio element found for {url}\")\n",
    "    \n",
    "    media_url = media_url\n",
    "    \n",
    "    # Get filename from URL\n",
    "    filename = os.path.basename(media_url)\n",
    "    filepath = os.path.join(save_path, post_data[\"base_filename\"] + \"_\" + filename)\n",
    "    \n",
    "    # Download the audio file\n",
    "    audio_content = requests.get(media_url).content\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(audio_content)\n",
    "\n",
    "    converted_filepath = filepath.replace(\".m4a\", \".mp4\")\n",
    "    convert_audio_to_video(filepath, converted_filepath)\n",
    "    os.remove(filepath)\n",
    "    \n",
    "    process = subprocess.run(\n",
    "        ['C:\\\\Tools\\\\videohashes-windows-amd64.exe',  '-json', '-md5', converted_filepath,], \n",
    "        capture_output=True,  # Captures both stdout and stderr\n",
    "        text=True  # Returns strings instead of bytes\n",
    "    )\n",
    "    assert process.returncode == 0, f\"Failed to run videohashes: {process.stderr}\"\n",
    "    videohashes_data = json.loads(process.stdout)\n",
    "    \n",
    "    soundgasm_title_element = soundgasm_soup.find('div', {'class': 'jp-title'})\n",
    "    soundgasm_title = soundgasm_title_element.text.strip() if soundgasm_title_element else None\n",
    "    soundgasm_description_element = soundgasm_soup.find('div', {'class': 'jp-description'})\n",
    "    soundgasm_description = soundgasm_description_element.text.strip() if soundgasm_description_element else None\n",
    "    \n",
    "    metadata = {\n",
    "        \"soundgasm\": {\n",
    "            \"media_url\": media_url,\n",
    "            \"title\": soundgasm_title,\n",
    "            \"description\": soundgasm_description\n",
    "        },\n",
    "        \"videohashes\": videohashes_data\n",
    "    }\n",
    "    \n",
    "    # Save similar submission JSON to filename.json\n",
    "    with open(f\"{filepath}.json\", \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    return (converted_filepath, metadata)\n",
    "        \n",
    "def download_scriptbin_script(post_data,url):\n",
    "    cookies = {\n",
    "        \"ta\": \"y\",\n",
    "        \"sbw.af\": \"CfDJ8MlNLnNvdf9Ll4Zq18iJsFwTaln_nTYl_FT-Xl6UpDBYBtNSuIuKvn68VIbziE4xd1zG1s2h9GqVyvCCR5a0iQ4GNGGHSPQZNvaTQQfc453ew8LyIH8FtVrGhbBJXOHgv73z9lqYnf5FbeppySm32DA\",\n",
    "        \"auth\": \"eyJuIjoiRUVzZmMvaFFzNVlLc1hKdSIsInAiOiJPS0FjWXRINDBxZHpwV29SektLL3dJL0NQSWpuTGRBTVU2QVNhU0M5SERHdWQ5VithVVlHdmZuOUdyWlpWc1BBNGRpOTJXVDRNMFl1azBIUHN6bFBSM0U9In0%3D\",\n",
    "        \"authpl\": \"1\",\n",
    "        \"sbw.ses\": \"CfDJ8MlNLnNvdf9Ll4Zq18iJsFzMzs%2BQKGDUdtevrXEl1xGWYKZn6cHnSdto06QeYAd0JxaZJIG9ERbyZlUCtSA6qQMAEdIKW4OOV1wiWFkUxIdNGidd4cRVY3f0vrs2Xu74EeFheuRlpKP4jWxQ4X8zzeSHj1LDf7VIsN4e19crav0c\"\n",
    "    }\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.cookies.update(cookies)\n",
    "\n",
    "    scriptbin_content = session.get(url)\n",
    "    scriptbin_content.text\n",
    "\n",
    "    script = {\n",
    "        \"scriptbin\": {\n",
    "            \"script_source_url\": url,\n",
    "            \"script_content\": scriptbin_content.text\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    filepath = os.path.join(save_path, post_data[\"base_filename\"] + \"_script.json\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(script, f)\n",
    "        \n",
    "    return (filepath, script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_url = \"https://old.reddit.com/r/gonewildaudio/comments/1eo25f0/f4m_girlfriend_gives_a_impromptu_encore/\"\n",
    "download_reddit_post(args_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stash_performer = stash.find_performer({ \n",
    "#     \"name\": submission.author.name,\n",
    "#     \"gender\": determine_performer_gender(submission.author_flair_text),\n",
    "#     \"image\": submission.author.icon_img\n",
    "# }, create=True)\n",
    "# stash_performer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Method 1: Capture both stdout and stderr\n",
    "\n",
    "\n",
    "print(\"STDOUT:\", process.stdout)\n",
    "print(\"STDERR:\", process.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
