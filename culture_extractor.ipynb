{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing metadata from Culture Extractor to StashApp\n",
    "# 1. Import metadata from Culture Extractor\n",
    "# 2. Import metadata from StashApp by oshash\n",
    "# 3. Join the two on oshash\n",
    "# 4. Query metadata from StashDB by phash\n",
    "# 5. Join the three on phash\n",
    "# 6. Match performers between Culture Extractor, StashApp and StashDB\n",
    "# 7. Set Culture Extractor UUIDs to performer custom fields in StashApp\n",
    "# 8. Set metadata to StashApp scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libraries.client_culture_extractor as client_culture_extractor\n",
    "import os\n",
    "import polars as pl\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Culture Extractor\n",
    "user = os.environ.get(\"CE_DB_USERNAME\")\n",
    "pw = os.environ.get(\"CE_DB_PASSWORD\")\n",
    "host = os.environ.get(\"CE_DB_HOST\")\n",
    "port = os.environ.get(\"CE_DB_PORT\")\n",
    "db = os.environ.get(\"CE_DB_NAME\")\n",
    "\n",
    "connection_string = f\"dbname={db} user={user} password={pw} host={host} port={port}\"\n",
    "\n",
    "culture_extractor_client = client_culture_extractor.ClientCultureExtractor(connection_string)\n",
    "\n",
    "\n",
    "# StashApp\n",
    "from libraries.client_stashapp import StashAppClient, get_stashapp_client\n",
    "\n",
    "stash_client = StashAppClient()\n",
    "stash_raw_client = get_stashapp_client()\n",
    "\n",
    "\n",
    "# StashDB\n",
    "from libraries.StashDbClient import StashDbClient\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "stashbox_client = StashDbClient(\n",
    "    os.getenv(\"STASHDB_ENDPOINT\"),\n",
    "    os.getenv(\"STASHDB_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "# Functions\n",
    "def hex_to_binary(hex_string):\n",
    "    return bin(int(hex_string, 16))[2:].zfill(64)\n",
    "\n",
    "def calculate_hamming_distance(phash1, phash2):\n",
    "    # Convert hexadecimal phashes to binary\n",
    "    binary1 = hex_to_binary(phash1)\n",
    "    binary2 = hex_to_binary(phash2)\n",
    "    \n",
    "    # Ensure both binary strings are of equal length\n",
    "    if len(binary1) != len(binary2):\n",
    "        raise ValueError(\"Binary strings must be of equal length\")\n",
    "    \n",
    "    # Calculate Hamming distance\n",
    "    return sum(c1 != c2 for c1, c2 in zip(binary1, binary2))\n",
    "\n",
    "# Example usage:\n",
    "# phash1 = \"951428607cf7cb8f\"\n",
    "# phash2 = \"951428607cf7cb8e\"\n",
    "# distance = calculate_hamming_distance(phash1, phash2)\n",
    "# print(f\"Hamming distance between {phash1} and {phash2}: {distance}\")\n",
    "\n",
    "def levenshtein(s1, s2):\n",
    "    if not s1:\n",
    "        return None\n",
    "    if not s2:\n",
    "        return None\n",
    "    from Levenshtein import distance\n",
    "    return distance(s1, s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = stash_raw_client.find_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = culture_extractor_client.get_sites()\n",
    "# Copy to clipboard\n",
    "sites.filter(pl.col(\"ce_sites_name\").str.contains(\"Nubile Films\")).select(pl.col(\"ce_sites_uuid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stash_client.set_studio_stash_id_for_endpoint(7, \"https://culture.extractor/graphql\", \"018e8ed6-21fe-739d-8019-4203505a6f86\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stash_studios = stash_client.get_studios()\n",
    "stash_studios.filter(pl.col(\"stash_studios_name\").str.contains(\"Nubile Films\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sites_joined = sites.join(stash_studios, left_on=\"ce_sites_name\", right_on=\"stash_studios_name\", how=\"left\", coalesce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refreshed_studio = stash_raw_client.find_studios(q=\"Nubile Films\", fragment=\"id, name, url, stash_ids { endpoint, stash_id, updated_at }\")\n",
    "stashapp_studio_id = refreshed_studio[0][\"id\"]\n",
    "refreshed_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads = culture_extractor_client.get_downloads('Nubile Films')\n",
    "downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oshashes = downloads[\"ce_downloads_hash_oshash\"].unique().to_list()\n",
    "stash_app_scenes = stash_client.find_scenes_by_oshash(oshashes)\n",
    "stash_app_scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_scenes = stash_app_scenes.join(downloads, left_on=\"stashapp_primary_file_oshash\", right_on=\"ce_downloads_hash_oshash\", how=\"left\", coalesce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store scene data\n",
    "scene_data = []\n",
    "\n",
    "# Create list of scene objects with filename, phash and duration\n",
    "scene_objects = joined_scenes.select(\n",
    "    pl.col(\"stashapp_primary_file_path\").alias(\"filename\"),\n",
    "    pl.col(\"stashapp_primary_file_phash\").alias(\"phash\"),\n",
    "    pl.col(\"stashapp_primary_file_duration\").dt.total_seconds().alias(\"duration\"),\n",
    ").to_dicts()\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "stashdb_scene_batches = []\n",
    "for i in range(0, len(scene_objects), batch_size):\n",
    "    batch = scene_objects[i:i+batch_size]\n",
    "    batch_stashdb_scenes = stashbox_client.query_scenes_by_phash(batch)\n",
    "    stashdb_scene_batches.append(batch_stashdb_scenes)\n",
    "\n",
    "df_stashdb_scenes = pl.concat(stashdb_scene_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_scenes = joined_scenes.join(df_stashdb_scenes, left_on=\"stashapp_primary_file_phash\", right_on=\"queried_phash\", how=\"left\", coalesce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = \"joined_scenes_with_stashdb_scenes_20250105_1715.parquet\"\n",
    "\n",
    "# joined_scenes_with_stashdb_scenes.write_parquet(parquet_path)\n",
    "joined_scenes = pl.read_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_duration_difference(stashapp_duration, stashdb_duration):\n",
    "    return (\n",
    "        pl.when(stashapp_duration.is_not_null() & stashdb_duration.is_not_null())\n",
    "        .then(\n",
    "            ((stashapp_duration - stashdb_duration).abs() / \n",
    "             pl.max_horizontal([stashapp_duration, stashdb_duration])) * 100\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "def calculate_title_similarity(ce_title, stashdb_title):\n",
    "    return (\n",
    "        pl.when(ce_title.is_not_null() & stashdb_title.is_not_null())\n",
    "        .then(\n",
    "            pl.struct([ce_title, stashdb_title])\n",
    "            .map_elements(\n",
    "                lambda row: levenshtein(str(row[0]), str(row[1])),  # Access by index instead of field name\n",
    "                return_dtype=pl.Int64\n",
    "            )\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "def get_date_difference_days(ce_date, stashdb_date):\n",
    "    return (\n",
    "        pl.when(ce_date.is_not_null() & stashdb_date.is_not_null())\n",
    "        .then(\n",
    "            (ce_date.cast(pl.Datetime) - stashdb_date.cast(pl.Datetime)).dt.total_days().abs()\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "# First create the calculated columns\n",
    "df_verification = joined_scenes.with_columns([\n",
    "    calculate_duration_difference(\n",
    "        pl.col(\"stashapp_primary_file_duration\"), \n",
    "        pl.col(\"duration\")\n",
    "    ).alias(\"duration_diff_pct\"),\n",
    "    \n",
    "    pl.struct([\"ce_downloads_release_name\", \"title\"])\n",
    "        .map_elements(lambda x: levenshtein(x[\"ce_downloads_release_name\"], x[\"title\"]), return_dtype=pl.Int64)\n",
    "        .alias(\"title_levenshtein\"),\n",
    "    \n",
    "    get_date_difference_days(\n",
    "        pl.col(\"ce_downloads_release_date\"),\n",
    "        pl.col(\"date\")\n",
    "    ).alias(\"date_diff_days\"),\n",
    "])\n",
    "\n",
    "# Then add the warning flags\n",
    "df_verification = df_verification.with_columns([\n",
    "    # Add warning flags\n",
    "    (pl.col(\"duration_diff_pct\") > 5).alias(\"duration_warning\"),\n",
    "    (pl.col(\"title_levenshtein\") > 5).alias(\"title_warning\"),\n",
    "    (pl.col(\"date_diff_days\") > 7).alias(\"date_warning\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_filtered = joined_scenes.filter(\n",
    "    (joined_scenes['stashapp_ce_id'].is_null()),\n",
    "    (joined_scenes['id'].is_not_null())\n",
    ")\n",
    "foo_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stashapp_performers = stash_client.get_performers()\n",
    "all_stashapp_performers = all_stashapp_performers.with_columns(\n",
    "    pl.col(\"stashapp_custom_fields\").list.eval(\n",
    "        pl.when(pl.element().struct.field(\"key\") == \"CultureExtractor.nubilefilms\")\n",
    "        .then(pl.element().struct.field(\"value\"))\n",
    "        .otherwise(None)\n",
    "    ).list.first().alias(\"ce_custom_field_value\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_performers = all_stashapp_performers.filter(pl.col(\"ce_custom_field_value\").is_null())\n",
    "unmatched_performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libraries.performer_matcher import PerformerMatcher\n",
    "\n",
    "# Create matcher instance\n",
    "matcher = PerformerMatcher(all_stashapp_performers)\n",
    "\n",
    "# Your DataFrame already has the required columns, but we need to process each row\n",
    "all_matches = []\n",
    "\n",
    "# Process each row in your DataFrame\n",
    "for row in joined_scenes.iter_rows(named=True):\n",
    "    # Get performers from both sources\n",
    "    ce_performers = row['ce_downloads_performers']\n",
    "    stashapp_performers = row['stashapp_performers']\n",
    "    \n",
    "    # Create single-row DataFrame for the matcher\n",
    "    scene_df = pl.DataFrame({\n",
    "        'ce_downloads_performers': [ce_performers],\n",
    "        'stashapp_performers': [stashapp_performers]\n",
    "    })\n",
    "    \n",
    "    # Run matching for this scene\n",
    "    matches = matcher.match_performers(\n",
    "        scene_df['ce_downloads_performers'],\n",
    "        scene_df['stashapp_performers']\n",
    "    )\n",
    "    \n",
    "    # Add scene context to matches\n",
    "    for match in matches:\n",
    "        all_matches.append({\n",
    "            'scene_id': row['stashapp_id'],\n",
    "            'scene_title': row['stashapp_title'],\n",
    "            'ce_uuid': match.ce_uuid,\n",
    "            'ce_name': match.ce_name,\n",
    "            'stashapp_id': match.stashapp_id,\n",
    "            'stashapp_name': match.stashapp_name,\n",
    "            'stashdb_uuid': match.stashdb_uuid,\n",
    "            'stashdb_name': match.stashdb_name,\n",
    "            'confidence': match.confidence,\n",
    "            'reason': match.reason\n",
    "        })\n",
    "\n",
    "# Convert matches to DataFrame for analysis\n",
    "matches_df = pl.DataFrame(all_matches)\n",
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in matches_df.select(pl.col([\"ce_uuid\", \"stashapp_id\"])).unique().iter_rows(named=True):\n",
    "    stash_client.update_performer_custom_fields(row[\"stashapp_id\"], {\"CultureExtractor.nubilefilms\": row[\"ce_uuid\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def create_update_dataframe(joined_scenes, downloads, all_stashapp_performers, all_tags, stashapp_studio_id):\n",
    "    # Get all scene data ready for updates\n",
    "    updates_df = joined_scenes.select([\n",
    "        pl.col(\"stashapp_id\").alias(\"scene_id\"),\n",
    "        pl.col(\"stashapp_primary_file_path\").alias(\"scene_name\"),\n",
    "        pl.col(\"ce_downloads_release_date\").alias(\"date\"),\n",
    "        pl.col(\"ce_downloads_release_name\").alias(\"title\"),\n",
    "        pl.col(\"ce_downloads_release_short_name\").alias(\"code\"),\n",
    "        pl.col(\"ce_downloads_release_description\").alias(\"details\"),\n",
    "        pl.lit(stashapp_studio_id).alias(\"studio_id\"),\n",
    "        pl.col(\"ce_downloads_release_url\").alias(\"url\"),\n",
    "        pl.col(\"ce_downloads_release_uuid\"),\n",
    "        pl.col(\"id\").alias(\"stashdb_id\"),\n",
    "        pl.col(\"ce_downloads_performers\"),\n",
    "        pl.col(\"tags\").alias(\"stashdb_tags\")\n",
    "    ])\n",
    "\n",
    "    # Map performers\n",
    "    updates_df = updates_df.with_columns([\n",
    "        pl.col(\"ce_downloads_performers\").map_elements(\n",
    "            lambda performers: [p[\"uuid\"] for p in performers],\n",
    "            return_dtype=pl.List(pl.Utf8)\n",
    "        ).alias(\"ce_performer_uuids\")\n",
    "    ])\n",
    "\n",
    "    # Get StashApp performer IDs\n",
    "    performer_mapping = all_stashapp_performers.filter(\n",
    "        pl.col(\"ce_custom_field_value\").is_not_null()\n",
    "    ).select([\n",
    "        pl.col(\"ce_custom_field_value\"),\n",
    "        pl.col(\"stashapp_id\")\n",
    "    ])\n",
    "\n",
    "    # Join performer IDs\n",
    "    updates_df = updates_df.with_columns([\n",
    "        pl.col(\"ce_performer_uuids\").map_elements(\n",
    "            lambda uuids: performer_mapping.filter(\n",
    "                pl.col(\"ce_custom_field_value\").is_in(uuids)\n",
    "            ).select(\"stashapp_id\").to_series().to_list(),\n",
    "            return_dtype=pl.List(pl.Int64)\n",
    "        ).alias(\"performer_ids\")\n",
    "    ])\n",
    "\n",
    "    # Map tags\n",
    "    tag_mapping = pl.DataFrame({\n",
    "        \"stashdb_name\": [tag[\"name\"] for tag in all_tags],\n",
    "        \"stashapp_id\": [tag[\"id\"] for tag in all_tags]\n",
    "    })\n",
    "\n",
    "    updates_df = updates_df.with_columns([\n",
    "        pl.col(\"stashdb_tags\").map_elements(\n",
    "            lambda tags: tag_mapping.filter(\n",
    "                pl.col(\"stashdb_name\").is_in([t[\"name\"] for t in tags])\n",
    "            ).select(\"stashapp_id\").to_series().to_list(),\n",
    "            return_dtype=pl.List(pl.Utf8)\n",
    "        ).alias(\"tag_ids\")\n",
    "    ])\n",
    "\n",
    "    # Get scene images\n",
    "    scene_images = downloads.filter(\n",
    "        pl.col(\"ce_downloads_file_type\") == \"image\"\n",
    "    ).select([\n",
    "        pl.col(\"ce_downloads_release_uuid\"),\n",
    "        pl.col(\"ce_downloads_saved_filename\").alias(\"scene_image_filename\")\n",
    "    ])\n",
    "\n",
    "    # Get gallery info\n",
    "    galleries = downloads.filter(\n",
    "        (pl.col(\"ce_downloads_content_type\") == \"gallery\") &\n",
    "        (pl.col(\"ce_downloads_variant\") == \"Large\")\n",
    "    ).select([\n",
    "        pl.col(\"ce_downloads_release_uuid\"),\n",
    "        pl.col(\"ce_downloads_hash_sha256\").alias(\"gallery_hash\")\n",
    "    ])\n",
    "\n",
    "    # Join images and galleries\n",
    "    updates_df = updates_df.join(\n",
    "        scene_images,\n",
    "        on=\"ce_downloads_release_uuid\",\n",
    "        how=\"left\"\n",
    "    ).join(\n",
    "        galleries,\n",
    "        on=\"ce_downloads_release_uuid\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return updates_df\n",
    "\n",
    "def generate_update_inputs(updates_df, stash_raw_client):\n",
    "    updates = []\n",
    "    \n",
    "    for row in updates_df.iter_rows(named=True):\n",
    "        # Get current scene data\n",
    "        refreshed_scene = stash_raw_client.find_scene(row[\"scene_id\"])\n",
    "        \n",
    "        # Load scene image\n",
    "        image_path = os.path.join(\n",
    "            \"F:\\\\Ripping\\\\Nubile Films\\\\Metadata\", \n",
    "            row[\"ce_downloads_release_uuid\"],\n",
    "            row[\"scene_image_filename\"]\n",
    "        )\n",
    "        scene_image_base64 = base64.b64encode(open(image_path, \"rb\").read()).decode(\"utf-8\")\n",
    "\n",
    "        # Find gallery if exists\n",
    "        gallery_id = None\n",
    "        gallery_urls = []\n",
    "        if row[\"gallery_hash\"]:\n",
    "            found_galleries = stash_raw_client.find_galleries(q=row[\"gallery_hash\"])\n",
    "            if len(found_galleries) == 1:\n",
    "                gallery_id = found_galleries[0][\"id\"]\n",
    "                refreshed_gallery = stash_raw_client.find_gallery(gallery_id)\n",
    "                gallery_urls = refreshed_gallery.get(\"urls\", [])\n",
    "\n",
    "        # Handle potentially null values\n",
    "        existing_tag_ids = [tag[\"id\"] for tag in refreshed_scene.get(\"tags\", [])]\n",
    "        new_tag_ids = row[\"tag_ids\"] if row[\"tag_ids\"] is not None else []\n",
    "        existing_urls = refreshed_scene.get(\"urls\", [])\n",
    "        new_url = [row[\"url\"]] if row[\"url\"] is not None else []\n",
    "        existing_stash_ids = refreshed_scene.get(\"stash_ids\", [])\n",
    "\n",
    "        scene_stash_ids = list({\n",
    "            (stash_id[\"endpoint\"], stash_id[\"stash_id\"]): stash_id\n",
    "            for stash_id in existing_stash_ids + [\n",
    "                {\n",
    "                    \"endpoint\": \"https://stashdb.org/graphql\",\n",
    "                    \"stash_id\": row[\"stashdb_id\"]\n",
    "                },\n",
    "                {\n",
    "                    \"endpoint\": \"https://culture.extractor/graphql\",\n",
    "                    \"stash_id\": row[\"ce_downloads_release_uuid\"]\n",
    "                }\n",
    "            ]\n",
    "        }.values())\n",
    "\n",
    "        update = {\n",
    "            \"scene_id\": row[\"scene_id\"],\n",
    "            \"scene_name\": row[\"scene_name\"],\n",
    "            \"gallery_id\": gallery_id,\n",
    "            \"date\": row[\"date\"].strftime(\"%Y-%m-%d\") if row[\"date\"] else None,\n",
    "            \"title\": row[\"title\"],\n",
    "            \"code\": row[\"code\"],\n",
    "            \"details\": row[\"details\"],\n",
    "            \"studio_id\": row[\"studio_id\"],\n",
    "            \"performer_ids\": row[\"performer_ids\"] if row[\"performer_ids\"] is not None else [],\n",
    "            \"tag_ids\": list(set(existing_tag_ids + new_tag_ids)),\n",
    "            \"scene_urls\": existing_urls + new_url,\n",
    "            \"gallery_urls\": (gallery_urls + [\n",
    "                row[\"url\"],\n",
    "                f\"https://culture.extractor/galleries/{row['ce_downloads_release_uuid']}\"\n",
    "            ]) if gallery_id else None,\n",
    "            \"cover_image\": f\"data:image/jpeg;base64,{scene_image_base64}\",\n",
    "            \"scene_stash_ids\": scene_stash_ids\n",
    "        }\n",
    "        updates.append(update)\n",
    "\n",
    "    return pl.DataFrame(updates)\n",
    "\n",
    "# Usage\n",
    "updates_df = create_update_dataframe(\n",
    "    foo_filtered,\n",
    "    downloads,\n",
    "    all_stashapp_performers,\n",
    "    all_tags,\n",
    "    stashapp_studio_id\n",
    ")\n",
    "\n",
    "update_inputs_df = generate_update_inputs(updates_df, stash_raw_client)\n",
    "\n",
    "# Review updates before applying\n",
    "print(\"Updates to be applied:\")\n",
    "print(update_inputs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply updates if everything looks good\n",
    "for update in update_inputs_df.iter_rows(named=True):\n",
    "    # Update scene\n",
    "    scene_input = {\n",
    "        \"id\": update[\"scene_id\"],\n",
    "        \"date\": update[\"date\"],\n",
    "        \"title\": update[\"title\"],\n",
    "        \"code\": update[\"code\"],\n",
    "        \"details\": update[\"details\"],\n",
    "        \"studio_id\": update[\"studio_id\"],\n",
    "        \"performer_ids\": update[\"performer_ids\"],\n",
    "        \"tag_ids\": update[\"tag_ids\"],\n",
    "        \"urls\": update[\"scene_urls\"],\n",
    "        \"cover_image\": update[\"cover_image\"],\n",
    "        \"stash_ids\": update[\"scene_stash_ids\"]\n",
    "    }\n",
    "    if update[\"gallery_id\"]:\n",
    "        scene_input[\"gallery_ids\"] = [update[\"gallery_id\"]]\n",
    "    \n",
    "    stash_raw_client.update_scene(scene_input)\n",
    "\n",
    "    # Update gallery if exists\n",
    "    if update[\"gallery_id\"]:\n",
    "        gallery_input = {\n",
    "            \"id\": update[\"gallery_id\"],\n",
    "            \"date\": update[\"date\"],\n",
    "            \"title\": update[\"title\"],\n",
    "            \"code\": update[\"code\"],\n",
    "            \"details\": update[\"details\"],\n",
    "            \"studio_id\": update[\"studio_id\"],\n",
    "            \"performer_ids\": update[\"performer_ids\"],\n",
    "            \"tag_ids\": update[\"tag_ids\"],\n",
    "            \"urls\": update[\"gallery_urls\"]\n",
    "        }\n",
    "        stash_raw_client.update_gallery(gallery_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
