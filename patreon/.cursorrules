# Cursor Rules for Patreon Scraper Project

## Code Style & Formatting

- **NEVER format Python code manually** - Always use Black for formatting
- Use `uv run black scripts/` or `python format.py` to format code
- Black configuration is in pyproject.toml (88 char line length, Python 3.8+ target)
- **Use Ruff for linting** - Fast, comprehensive linter that replaces multiple tools
- Use `uv run ruff check scripts/` to check for issues
- Use `uv run ruff check --fix scripts/` to auto-fix many issues
- Ruff configuration is in pyproject.toml with comprehensive rule sets
- Pre-commit hooks will automatically format code and run linting before commits
- Follow PEP 8 naming conventions (snake_case for functions/variables, PascalCase for classes)

## Python Best Practices

- Use Python 3.8+ compatible syntax and features
- Prefer type hints for function parameters and return values
- Use descriptive variable and function names
- Add docstrings for all public functions and classes
- Handle exceptions gracefully with specific exception types
- Use context managers (with statements) for file operations and resource management

## Project-Specific Guidelines

### Dependencies & Package Management

- Use `uv` for dependency management, not pip
- Add new dependencies to pyproject.toml under [project.dependencies] or [tool.uv.dev-dependencies]
- Use `uv sync` to install dependencies
- Use `uv run` to execute Python scripts

### Data Handling

- Use Polars for data manipulation instead of pandas when possible
- Store processed data in data/ directory
- Use Parquet format for efficient data storage
- Handle large datasets with streaming/chunking when necessary

### File Organization

- Main scripts go in scripts/ directory
- Store processed data in data/ directory
- Downloaded media goes in media/ directory
- Exclude data/, captured/, and media/ from version control

### HTTP & Web Scraping

- Implement proper rate limiting to respect server resources
- Use session management for authenticated requests
- Handle HTTP errors gracefully with retries
- Validate captured data before processing

### Error Handling & Logging

- Use descriptive error messages
- Log important operations and errors
- Provide helpful error messages for common issues
- Use try-except blocks for external API calls

## Code Organization

### Function Design

- Keep functions focused on single responsibilities
- Use early returns to reduce nesting
- Validate inputs at function entry points
- Return consistent data types
- Use generator functions for large data processing

### Class Design

- Use classes for stateful operations (scrapers, data processors)
- Implement **str** and **repr** methods for debugging
- Use property decorators for computed attributes
- Follow composition over inheritance

### Import Organization

- Group imports: standard library, third-party, local imports
- Use absolute imports for project modules
- Avoid wildcard imports (from module import \*)

## Code Quality & Linting

- **Use Ruff for comprehensive linting** - Covers pyflakes, pycodestyle, isort, and more
- Run `uv run ruff check scripts/` before committing code
- Focus on F821/F822/F823 errors for function definition order issues
- Use `uv run ruff check --fix scripts/` to auto-fix formatting and import issues
- Ruff replaces multiple tools: flake8, isort, pyupgrade, and more
- Configuration in pyproject.toml includes rules for code modernization and bug prevention

## Testing & Development

- Use validate_capture.py to validate captured data
- Write unit tests for core functionality
- Use meaningful test data and assertions
- Mock external API calls in tests
- Run linting checks before testing to catch issues early

## Security & Privacy

- Don't commit sensitive data to version control
- Validate and sanitize file paths
- Use secure file permissions for sensitive data
- Respect robots.txt and terms of service

## Performance Considerations

- Use Polars for large dataset operations
- Implement streaming for large file processing
- Cache expensive computations when appropriate
- Use async/await for I/O bound operations when beneficial
- Monitor memory usage for large datasets

## Documentation

- Update README.md when adding new features
- Document command-line arguments and options
- Include usage examples in docstrings
- Keep USAGE.md updated with workflow changes
- Document data formats and schemas

## Git & Version Control

- Use descriptive commit messages following conventional commit format
- **Commit Message Format**: Use multiple `-m` flags for clean multi-line messages
  - `git commit -m "feat: Clear title (50 chars max)" -m "- Bullet point 1" -m "- Bullet point 2"`
  - **Avoid** single long lines or empty lines between bullet points
  - Use conventional prefixes: feat:, fix:, docs:, refactor:, test:, chore:
- **Use non-interactive git commands** to avoid pagers (less, more, etc.)
  - Use `git log --oneline` instead of `git log`
  - Use `git show --no-patch` for commit messages without diffs
  - Use `git diff --no-pager` or `git --no-pager diff` for diffs
  - Add `--no-pager` flag or `| cat` to avoid interactive pagers
  - Example: `git log --oneline -10` for recent commits without pager
- Run pre-commit hooks before committing
- Don't commit generated files (data/, media/, captured/)
- Use .gitignore to exclude sensitive and generated files
- Create feature branches for significant changes
- Always provide a git commit message for the user

## Command Line Interface

- Use argparse for command-line argument parsing
- Provide helpful help messages and examples
- Support both required and optional arguments
- Validate command-line inputs
- Provide sensible defaults for optional parameters

## Data Export & Analysis

- Use JSON format for data export
- Generate summary reports and statistics
- Implement data validation and quality checks
- Use consistent data schemas for exports
- Provide data analysis utilities and examples

Remember: This project is for educational and research purposes. Always comply with Patreon's terms of service and applicable laws.
